{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860306de-b6e7-4d4c-8779-c0ccdb5fa060",
   "metadata": {},
   "source": [
    "Clustering is an unsupervised learning technique that groups similar data points into clusters based on their features. The goal is to identify patterns or structures in the data without prior knowledge of class labels. Examples:\n",
    "- **Customer Segmentation:** Group customers by demographics, behavior, or preferences to target marketing efforts.\n",
    "- **Image Segmentation:** Cluster pixels in an image to identify objects or regions.\n",
    "- **Gene Expression Analysis:** Cluster genes based on their expression levels to identify co-regulated genes.\n",
    "- **Anomaly Detection:** Identify outliers or unsual patterns in data using clustering algorithms.\n",
    "\n",
    "**K-Means Algorithm** a popular clustering algorithm that partitions the data into $K$ clusters based on their mean distances. It iteratively updates the cluster centroids (mean points) and reassigns data points to the closest cluster until convergence.\n",
    "\n",
    "**How it Works:**\n",
    "1. Initialize $K$ cluster centroids randomly.\n",
    "2. Assign each data point to the closest centroid based on Euclidean distance.\n",
    "3. Update the centroid of each cluster by calculating the mean of all data points assigned to it.\n",
    "4. Repeat steps 2-3 until the centroids converge or a stopping criterion is reached.\n",
    "\n",
    "Increasing the number of clusters ($K$) allows for more detailed clustering, but may lead to overfitting r noisy clusters. Decreasing $K$ may result in underfitting or loss of important patterns. The centroids represent the mean points of each cluster. As the number of clusters changes, the centroids adjust to reflect the new cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2284ea7-7007-4a47-8ad7-7e6bbc13d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from ipywidgets import interact, IntSlider\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fedfc07-bc2b-443b-8b42-0156faffcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] # We'll use only the first two features for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69deee57-fa0c-448a-ac0f-4c635709eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for interactive clustering visualization\n",
    "def plot_kmeans_clusters(num_clusters=2):\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Plot data points for each cluster\n",
    "    for i in range(num_clusters):\n",
    "        plt.scatter(X[labels == i, 0], X[labels == i, 1], label=f'Cluster {i + 1}')\n",
    "    # Plot all centroids once\n",
    "    plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "                s=200, c='black', marker='X', label='Centroids')\n",
    "    \n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(f'K-Means Clustering (Number of Clusters: {num_clusters})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73baf32-99a5-4433-9baf-84d428a02a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2cb84fbee549698296f268c2ea95ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=2, description='Number of Clusters', max=5, min=2), Output()), _dom_clas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_kmeans_clusters(num_clusters=2)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a slider for adjusting the number of clusters\n",
    "num_clusters_slider = IntSlider(value=2, min=2, max=5, description='Number of Clusters')\n",
    "\n",
    "# Create an interactive widget\n",
    "interact(plot_kmeans_clusters, num_clusters=num_clusters_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65385e92-7ac0-4922-8699-a5b2c1a55467",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- The model groups data points into clusters based on feature similarity without using labels (unsupervised learning).\n",
    "- Increasing the number of clusters results in smaller, more focused groups but can lead to over-segmentation.\n",
    "- The cluster centroids represent the mean position of points in each cluster, helping visualize cluster centers.\n",
    "\n",
    "### Analogy for Better Understanding\n",
    "- Students enter a classroom through different doors and sit freely where they feel most comfortable—usually near friends or familiar faces—forming one big natural group.\n",
    "- The teacher observes this seating to understand how students naturally cluster by affinity, noting strengths and weaknesses within the group.\n",
    "- Using these observations, the teacher divides the class into smaller groups, arranging desks into clusters that balance and optimize learning—similar to calculating centroids in K-Means clustering.\n",
    "- Over time, the teacher adjusts these groups based on ongoing observation and class dynamics, allowing clusters to stabilize into effective teams.\n",
    "- This process mirrors how K-Means starts with data points together, then iteratively forms clusters by assigning points to centroids, recalculating them, and refining groupings for cohesion.\n",
    "- Like building a strong team, clustering seeks to find natural, balanced groups through repeated refinement.\n",
    "\n",
    "---\n",
    "1. Multivariate Classification (Supervised) - Understand the complexity of labeled input features.\n",
    "2. MLP (Deep) - See how the model handles that complexity to predict correctly.\n",
    "3. K- Means (Unsepervised) - Group data by similarity to discover natural clusters without labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
